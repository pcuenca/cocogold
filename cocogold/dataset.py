# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/coco-semantic.ipynb.

# %% auto 0
__all__ = ['Rect', 'class_name', 'class_id', 'get_patch', 'segmented_mask', 'segment_pairs', 'random_square_crop_and_resize',
           'transformed_segments', 'is_contained', 'is_partially_contained', 'semantic_transformed_segments',
           'is_crowd', 'is_valid', 'crop_around_annotation', 'class_ids', 'CocoGoldDataset', 'CocoGoldIterableDataset']

# %% ../nbs/coco-semantic.ipynb 3
import matplotlib.pyplot as plt
from pycocotools.coco import COCO
from PIL import Image

# %% ../nbs/coco-semantic.ipynb 10
def class_name(class_id, cats):
    for i in range(len(cats)):
        if cats[i]['id'] == class_id:
            return cats[i]['name']
    return "None"

# %% ../nbs/coco-semantic.ipynb 13
def class_id(class_name, cats):
    for i in range(len(cats)):
        if cats[i]['name'] == class_name:
            return cats[i]['id']
    return -1

# %% ../nbs/coco-semantic.ipynb 34
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.path import Path
import numpy as np

def get_patch(landmarks, color='white', closed=False):
    contour = landmarks
    ops = [Path.MOVETO] + [Path.LINETO]*(len(contour)-1)
    facecolor = (0, 0, 0, 0)      # Transparent fill color, if open
    if closed:
        contour.append(contour[0])
        ops.append(Path.CLOSEPOLY)
        facecolor = color
    path = Path(contour, ops)
    # Disable antialiasing to keep only 0 and 1 values
    return patches.PathPatch(path, facecolor=facecolor, edgecolor=color, lw=4, antialiased=False)

def segmented_mask(segments, width=512, height=512):
    # Precisely control output image size
    dpi = 72
    fig, ax = plt.subplots(1, figsize=[width/dpi, height/dpi], tight_layout={'pad':0})
    fig.set_dpi(dpi)

    black = np.zeros((height, width, 3))
    ax.imshow(black)

    if not any(isinstance(item, list) for item in segments):
        segments = [segments]
        
    for segment in segments:
        patch = get_patch(segment, closed=True)
#        print(f"Path bounding box: {patch.get_extents()}")
        ax.add_patch(patch)

    plt.axis('off')    
    fig.canvas.draw()
    buffer, (c_width, c_height) = fig.canvas.print_to_buffer()
    assert c_width == width
    assert c_height == height
    
    buffer = np.frombuffer(buffer, np.uint8).reshape((height, width, 4))
    buffer = buffer[:, :, 0:3]
    plt.close(fig)
    return Image.fromarray(buffer)

# %% ../nbs/coco-semantic.ipynb 37
def segment_pairs(coordinates_list):
    """
    Convert a flat list of coordinates into a list of 2D pairs.
    The last item is discarded if the len is odd.
    """
    return list(zip(coordinates_list[::2], coordinates_list[1::2]))

# %% ../nbs/coco-semantic.ipynb 54
import random

def random_square_crop_and_resize(pilimg, size=512, generator=None):
    """
    Will downsample or upsample as necessary.
    Returns a dict with the image, the crop rect and the scale factor.
    """
    if generator is None:
        generator = random.Random()
    width, height = pilimg.size
    minsize = min(width, height)
    x0 = generator.randint(0, width - height) if width > height else 0
    y0 = generator.randint(0, height - width) if height > width else 0
    pilimg = pilimg.crop((x0, y0, x0 + minsize, y0 + minsize))
    pilimg = pilimg.resize((size, size), resample=Image.LANCZOS)
    return {
        "resized_image": pilimg,
        "crop_rect": (x0, y0, x0+minsize, y0+minsize),
        "scale": float(size)/minsize
    }

# %% ../nbs/coco-semantic.ipynb 62
def transformed_segments(segmentation, crop_rect, scale):
    segments = segment_pairs(segmentation)
    
    def transform_segment(segment):
        x, y = segment
        x = x - crop_rect[0]
        y = y - crop_rect[1]
        return x*scale, y*scale
    
    segments = map(lambda s: transform_segment(s), segments)
    return list(segments)

# %% ../nbs/coco-semantic.ipynb 67
import math
from collections import namedtuple
from functools import partial

Rect = namedtuple("Rect", "x0 y0 x1 y1")

# %% ../nbs/coco-semantic.ipynb 68
def is_contained(annotation, crop_rect):
    """Returns true if the annotation is fully contained inside the crop_rect."""
    crop_x0, crop_y0, crop_x1, crop_y1 = crop_rect
    bbox = annotation["bbox"]
    x0, y0, x1, y1 = (bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3])
    contained =               x0 >= crop_x0
    contained = contained and y0 >= crop_y0
    contained = contained and x1 <= crop_x1
    contained = contained and y1 <= crop_y1
    return contained

# %% ../nbs/coco-semantic.ipynb 69
def is_partially_contained(annotation, crop_rect):
    """
    Returns true if:
    - The bounding boxes overlap at least 75%
    - Or the cropped annotation bbox takes more than 15% of the crop_rect area
    """
    crop = Rect(*crop_rect)
    bbox = annotation["bbox"]
    rect = Rect(bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3])
    
    # Using the bbox area instead of the polygon's
    bbox_area = (rect.x1 - rect.x0) * (rect.y1 - rect.y0)
    crop_area = (crop.x1 - crop.x0) * (crop.y1 - crop.y0)
    if bbox_area == 0 or crop_area == 0:
        return False
    
    dx = min(crop.x1, rect.x1) - max(crop.x0, rect.x0)
    dy = min(crop.y1, rect.y1) - max(crop.y0, rect.y0)
    if (dx >= 0) and (dy >= 0):
        if (dx*dy)/bbox_area >= 0.75: return True
        return (dx*dy)/crop_area >= 0.15
    return False

# %% ../nbs/coco-semantic.ipynb 79
def semantic_transformed_segments(annotations, annotation, crop_rect, scale):
    """Return a list of transformerd segments for all the instances
    with the same class of the given annotation."""

    same_class_instances = list(filter(lambda a: a["category_id"] == annotation["category_id"], annotations))
    instances_segments = [s for a in same_class_instances for s in a["segmentation"]]

    return [transformed_segments(s, crop_rect, scale) for s in instances_segments]

# %% ../nbs/coco-semantic.ipynb 96
import torch
from torch.utils.data import Dataset

# %% ../nbs/coco-semantic.ipynb 97
def is_crowd(annotation):
    return "counts" in annotation["segmentation"]

def is_valid(annotation, crop_rect):
    return is_partially_contained(annotation, crop_rect) and not is_crowd(annotation)

# %% ../nbs/coco-semantic.ipynb 98
import math

def crop_around_annotation(annotation, pilimg, size=512, generator=None):
    bbox = annotation["bbox"]
    # print(class_name(annotation["category_id"], cats))
    # print(annotation)
    x, y, w, h = (math.floor(bbox[0]), math.floor(bbox[1]), round(bbox[2]), round(bbox[3]))

    if generator is None:
        generator = random.Random()

    width, height = pilimg.size
    minsize = min(width, height)
    if width > height:
        # print("left")
        if width - height > x:
            # Free band ends beyond the beginning of the ann -> avoid clipping
            x0 = generator.randint(0, x)
        else:
            # Select "from the right"
            x0 = generator.randint(x - minsize + w, width - minsize)
        y0 = 0
    else:
        # print("right")
        x0 = 0
        if height - width > y:
            # Free band ends beyond the beginning of the ann -> avoid clipping
            y0 = generator.randint(0, y)
        else:
            # Select "from the bottom"
            y0 = generator.randint(y - minsize + h, height - minsize)
        
    pilimg = pilimg.crop((x0, y0, x0 + minsize, y0 + minsize))
    pilimg = pilimg.resize((size, size), resample=Image.LANCZOS)
    return {
        "resized_image": pilimg,
        "crop_rect": (x0, y0, x0+minsize, y0+minsize),
        "scale": float(size)/minsize
    }

# %% ../nbs/coco-semantic.ipynb 102
from functools import partial

def class_ids(names, cats):
    name_to_id = partial(class_id, cats=cats)
    return list(filter(lambda x: x!= -1, map(name_to_id, names)))

# %% ../nbs/coco-semantic.ipynb 107
class CocoGoldDataset(Dataset):
    """
    A dataset for COCO 2017 semantic segmentation, suitable for Marigold training (hopefully).
    
    Items are a dictionary containing:
    - A random crop of the original image.
    - A segmentation mask for one random category of an instance inside the crop.
    - The class name of the segmentation mask.

    When return_type is "pil", images will be returned for the original and the mask. In this case, the mask background will be zero (black),
    and the mask foreground (subject) will be 1 (white).
    
    If return_type is "pt", the original image will be converted to a PyTorch tensor and normalized to `[-1, 1]`,
    and the mask will consist of `-1` values for the background and `1` for the subject. Images and masks have 
    shapes `[3, H, W]`.
    
    In both cases, masks contain three identical channels.

    You can pass a list of valid categories (as labels) in `valid_cat_names`.
    
    Note that results will be different each time you iterate. Larger subjects are selected with higher probability.
    """
    
    def __init__(self, dataset_root, split="val", size=512, max_items=None, valid_cat_names=None, return_type="pil", seed=1337):
        self.path = dataset_root
        self.split = split
        self.size = size
        if return_type not in ["pil", "pt"]:
            raise ValueError("Return type must be 'pil' or 'pt'")
        self.return_type = return_type
        annotations_path = f"{self.path}/annotations/instances_{split}2017.json"
        self.coco = COCO(annotations_path)
        self.cats = self.coco.loadCats(self.coco.getCatIds())  # all cats
        if valid_cat_names is None:
            self.valid_cats = set(map(lambda x: x["id"], self.cats))
        else:
            self.valid_cats = set(class_ids(valid_cat_names, self.cats))
        # Request all images, otherwise we just get a few for some reason. We filter later.
        self.imgs = self.coco.getImgIds()
        self._remove_empty()
        self._remove_small()
        if max_items is not None and max_items < len(self.imgs):
            generator = random.Random(seed) if seed is not None else random.Random()
            self.imgs = generator.sample(self.imgs, max_items)
        self.shuffle(seed)

    def _remove_empty(self):
        print("Filtering images with no supported annotations")
        def has_annotations(img_id):
            ann_ids = self.coco.getAnnIds(img_id)
            anns = self.coco.loadAnns(ann_ids)
            anns = list(filter(lambda x: x["category_id"] in self.valid_cats, anns))
            return len(anns) > 0
        
        self.imgs = [img for img in self.imgs if has_annotations(img)]

    def _remove_empty_old(self):
        print("Filtering images with no annotations")
        def has_annotations(img_id):
            ann_ids = self.coco.getAnnIds(img_id)
            return len(ann_ids) > 0
        
        self.imgs = [img for img in self.imgs if has_annotations(img)]

    # Some images have aspect ratios like 4:1, with width=640, height=160
    # with very visible artifacts that are made worse when upscaling
    def _remove_small(self, threshold=300):
        print("Filtering images whose height or width < 300")
        
        def is_small(img_id):
            img_info = self.coco.loadImgs(img_id)[0]
            if img_info["width"] < threshold:
                return True
            if img_info["height"] < threshold:
                return True
            return False
        
        self.imgs = [img for img in self.imgs if not is_small(img)]

    def __len__(self):
        return len(self.imgs)
    
    def resized(self, img_info):
        """Return a tuple resized_image, crop_rect and scale"""
        pilimg = Image.open(f"{self.path}/images/{self.split}/{img_info['file_name']}")    
        resized_dict = random_square_crop_and_resize(pilimg, size=self.size, generator=self.generator)
        return resized_dict["resized_image"], resized_dict["crop_rect"], resized_dict["scale"]

    def resized_around_ann(self, ann, img_info):
        """Return a tuple resized_image, crop_rect and scale that contains the annotation"""
        pilimg = Image.open(f"{self.path}/images/{self.split}/{img_info['file_name']}")    
        resized_dict = crop_around_annotation(ann, pilimg, size=self.size, generator=self.generator)
        return resized_dict["resized_image"], resized_dict["crop_rect"], resized_dict["scale"]

    def random_annotation_proportional_to_area(self, anns):
        min_area = max_area = anns[0]["area"]
        for annotation in anns[1:]:
            area = annotation["area"]
            min_area = min(area, min_area)
            max_area = max(area, max_area)
        indices = []
        for i, annotation in enumerate(anns):
            area = annotation["area"]
            reps = round(1 + math.log2(area/min_area))
            indices.extend([i] * reps)
        return anns[self.generator.choice(indices)]

    def shuffle(self, seed):
        """Shuffles, and also sets generator for other random ops"""
        indices = list(range(len(self.imgs)))
        # Use a default seed for reproducibility
        # TODO: verify that subsequent iterations after creating a dataloader produce the same sequence
        # TODO: use a different seed for each epoch
        self.generator = random.Random(seed) if seed is not None else random.Random(1337)
        if seed is not None:
            self.generator.shuffle(indices)
        self.shuffled = indices

    def _do_getitem(self, idx):
        img = self.imgs[self.shuffled[idx]]
        anns = self.coco.loadAnns(self.coco.getAnnIds(img))
        # Skip annotations of unsupported categories
        anns = list(filter(lambda x: x["category_id"] in self.valid_cats, anns))
        img_info = self.coco.loadImgs(img)[0]
        
        # Crop, then filter contained and not `iscrowd` annotations, assign probabilities according to area
        # Retry a few times in case our crop does not contain any valid annotations
        for _ in range(5):
            pilimg, crop_rect, scale = self.resized(img_info)
            contained_fn = partial(is_valid, crop_rect=crop_rect)
            contained = list(filter(contained_fn, anns))
            if len(contained) > 0: break

        # If we still have no annotations, select an annotation and crop around it
        if len(contained) == 0:
            selected_ann = None
            for ann in anns:
                pilimg, crop_rect, scale = self.resized_around_ann(ann, img_info)
                # contained_fn is also used later on, we need to update
                contained_fn = partial(is_valid, crop_rect=crop_rect)
                if contained_fn(ann):
                    selected_ann = ann
                    break
            if selected_ann is None:
                raise Exception("Could not select annotation")

            contained = [selected_ann]
            # print("Actually contained:", contained_fn(ann))

        annotation = self.random_annotation_proportional_to_area(contained)

        # Gather segments from all instances of the same class as the selected choice
        # but consider only valid annotations
        valid_anns = list(filter(contained_fn, anns))
        segments = semantic_transformed_segments(valid_anns, annotation, crop_rect, scale)
        
        # The following would just extract the selected instance
        # segments = transformed_segments(annotation["segmentation"][0], crop_rect, scale)
        
        mask = segmented_mask(segments, width=self.size, height=self.size)
        
        category = class_name(annotation["category_id"], self.cats)

        if self.return_type == "pt":
            pilimg = torch.tensor(np.array(pilimg.convert("RGB"), dtype=np.float32).transpose(2, 0, 1) / 255.0 * 2.0 - 1.0)
            mask = torch.tensor(np.array(mask, dtype=np.float32).transpose(2, 0, 1) / 255.0 * 2.0 - 1.0)
    
        return {
            "key": idx,
            "filename": img_info['file_name'],
            "image": pilimg,
            "mask": mask,
            "class": category,
        }

    def __getitem__(self, idx):
        if idx >= len(self):
            raise IndexError
        try:
            return self._do_getitem(idx)
        except Exception as e:
            print(f"Exception (will be ignored) on {idx}: {e}")
            return None

# %% ../nbs/coco-semantic.ipynb 129
from torch.utils.data import IterableDataset

class CocoGoldIterableDataset(IterableDataset):
    """
    Please, refer to the docstring of CocoGoldDataset.
    This is just an iterable wrapper that skips `None` values.
    If seed is not None, the dataset willa be shuffled with that seed.
    """
    
    def __init__(self, dataset_root, split="val", size=512, max_items=None, valid_cat_names=None, return_type="pil", seed=1337):
        super().__init__()
        self.dataset = CocoGoldDataset(dataset_root, split=split, size=size, max_items=max_items, valid_cat_names=valid_cat_names, return_type=return_type, seed=seed)
        self.seed = seed

    def __iter__(self):
        self.dataset.shuffle(self.seed)
        for item in self.dataset:
            if item is not None:
                yield item

    def __len__(self):
        return len(self.dataset)
